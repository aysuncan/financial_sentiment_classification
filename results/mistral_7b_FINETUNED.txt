METHOD: mistral_7b_FINETUNED


Processing Financial Phrasebank Dataset ...
              precision    recall  f1-score   support

    negative       0.92      0.94      0.93        49
     neutral       0.90      0.92      0.91       287
    positive       0.86      0.81      0.84       149

    accuracy                           0.89       485
   macro avg       0.89      0.89      0.89       485
weighted avg       0.89      0.89      0.89       485

accuracy: 0.8907216494845361
Confusion Matrix (Columns are predictions)
=======================================
[[ 46   3   0]
 [  3 265  19]
 [  1  27 121]]
=======================================



Processing Twitter Financial News Sentiment Dataset ...
              precision    recall  f1-score   support

    negative       0.84      0.87      0.86       347
     neutral       0.93      0.92      0.93      1566
    positive       0.85      0.86      0.86       475
   undefined       0.00      0.00      0.00         0

    accuracy                           0.90      2388
   macro avg       0.66      0.66      0.66      2388
weighted avg       0.90      0.90      0.90      2388

accuracy: 0.9015912897822446
Confusion Matrix (Columns are predictions)
=======================================
[[ 301   42    3    1]
 [  55 1442   69    0]
 [   1   64  410    0]
 [   0    0    0    0]]
=======================================





Processing Financial Opinion Mining and_Question Answering Dataset ...
              precision    recall  f1-score   support

    negative       0.61      0.87      0.72        31
     neutral       0.85      0.71      0.77        86
    positive       0.71      0.73      0.72        33

    accuracy                           0.75       150
   macro avg       0.72      0.77      0.74       150
weighted avg       0.77      0.75      0.75       150

accuracy: 0.7466666666666667
Confusion Matrix (Columns are predictions)
=======================================
[[27  3  1]
 [16 61  9]
 [ 1  8 24]]
=======================================




Processing News with GPT Instructions Dataset ...
              precision    recall  f1-score   support

    negative       0.71      0.76      0.73       808
     neutral       0.67      0.57      0.62      1671
    positive       0.72      0.81      0.76      1568
   undefined       0.00      0.00      0.00         0

    accuracy                           0.70      4047
   macro avg       0.53      0.54      0.53      4047
weighted avg       0.70      0.70      0.70      4047

accuracy: 0.701507289350136
Confusion Matrix (Columns are predictions)
=======================================
[[ 613  171   23    1]
 [ 244  949  478    0]
 [   5  286 1277    0]
 [   0    0    0    0]]
=======================================